{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d0ad264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ebc245f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>BP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Na_to_K</th>\n",
       "      <th>Drug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>F</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>25.355</td>\n",
       "      <td>DrugY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>M</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>13.093</td>\n",
       "      <td>drugC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>M</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>10.114</td>\n",
       "      <td>drugC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>F</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>7.798</td>\n",
       "      <td>drugX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61</td>\n",
       "      <td>F</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>18.043</td>\n",
       "      <td>DrugY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Sex      BP Cholesterol  Na_to_K   Drug\n",
       "0   23   F    HIGH        HIGH   25.355  DrugY\n",
       "1   47   M     LOW        HIGH   13.093  drugC\n",
       "2   47   M     LOW        HIGH   10.114  drugC\n",
       "3   28   F  NORMAL        HIGH    7.798  drugX\n",
       "4   61   F     LOW        HIGH   18.043  DrugY"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\ASUS\\OneDrive\\Desktop\\code\\datasets\\drug200.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2761b18f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>BP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Na_to_K</th>\n",
       "      <th>Drug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Age, Sex, BP, Cholesterol, Na_to_K, Drug]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f35dc705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>BP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Na_to_K</th>\n",
       "      <th>Drug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DrugY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>104</td>\n",
       "      <td>77</td>\n",
       "      <td>103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>44.315000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.084485</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16.544315</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.223956</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.269000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.445500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.936500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>58.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.380000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>74.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.247000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Age  Sex    BP Cholesterol     Na_to_K   Drug\n",
       "count   200.000000  200   200         200  200.000000    200\n",
       "unique         NaN    2     3           2         NaN      5\n",
       "top            NaN    M  HIGH        HIGH         NaN  DrugY\n",
       "freq           NaN  104    77         103         NaN     91\n",
       "mean     44.315000  NaN   NaN         NaN   16.084485    NaN\n",
       "std      16.544315  NaN   NaN         NaN    7.223956    NaN\n",
       "min      15.000000  NaN   NaN         NaN    6.269000    NaN\n",
       "25%      31.000000  NaN   NaN         NaN   10.445500    NaN\n",
       "50%      45.000000  NaN   NaN         NaN   13.936500    NaN\n",
       "75%      58.000000  NaN   NaN         NaN   19.380000    NaN\n",
       "max      74.000000  NaN   NaN         NaN   38.247000    NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45c01fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'drugC', 'drugA', 'DrugY', 'drugX', 'drugB'} {'LOW', 'HIGH', 'NORMAL'} {'HIGH', 'NORMAL'}\n"
     ]
    }
   ],
   "source": [
    "a=set(df['Drug'])\n",
    "b=set(df['BP'])\n",
    "c=set(df['Cholesterol'])\n",
    "print(a,b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28beceb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import get_dummies\n",
    "dfv2=get_dummies(df,columns=['Sex','BP','Cholesterol','Drug'],dtype=\"float\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db9e2279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Na_to_K</th>\n",
       "      <th>Sex_F</th>\n",
       "      <th>Sex_M</th>\n",
       "      <th>BP_HIGH</th>\n",
       "      <th>BP_LOW</th>\n",
       "      <th>BP_NORMAL</th>\n",
       "      <th>Cholesterol_HIGH</th>\n",
       "      <th>Cholesterol_NORMAL</th>\n",
       "      <th>Drug_DrugY</th>\n",
       "      <th>Drug_drugA</th>\n",
       "      <th>Drug_drugB</th>\n",
       "      <th>Drug_drugC</th>\n",
       "      <th>Drug_drugX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>25.355</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>13.093</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>10.114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>7.798</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61</td>\n",
       "      <td>18.043</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Na_to_K  Sex_F  Sex_M  BP_HIGH  BP_LOW  BP_NORMAL  Cholesterol_HIGH  \\\n",
       "0   23   25.355    1.0    0.0      1.0     0.0        0.0               1.0   \n",
       "1   47   13.093    0.0    1.0      0.0     1.0        0.0               1.0   \n",
       "2   47   10.114    0.0    1.0      0.0     1.0        0.0               1.0   \n",
       "3   28    7.798    1.0    0.0      0.0     0.0        1.0               1.0   \n",
       "4   61   18.043    1.0    0.0      0.0     1.0        0.0               1.0   \n",
       "\n",
       "   Cholesterol_NORMAL  Drug_DrugY  Drug_drugA  Drug_drugB  Drug_drugC  \\\n",
       "0                 0.0         1.0         0.0         0.0         0.0   \n",
       "1                 0.0         0.0         0.0         0.0         1.0   \n",
       "2                 0.0         0.0         0.0         0.0         1.0   \n",
       "3                 0.0         0.0         0.0         0.0         0.0   \n",
       "4                 0.0         1.0         0.0         0.0         0.0   \n",
       "\n",
       "   Drug_drugX  \n",
       "0         0.0  \n",
       "1         0.0  \n",
       "2         0.0  \n",
       "3         1.0  \n",
       "4         0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfv2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf306840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col=list(dfv2.columns)\n",
    "ycol=[]\n",
    "[ycol.append(x) for x in col if x.startswith('Drug')]\n",
    "[col.remove(x) for x in ycol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a9a7774",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dfv2[col]\n",
    "Y=dfv2[ycol]\n",
    "\n",
    "xarray=np.array(X)\n",
    "yarray=np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09fec4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(xarray, yarray, test_size=0.2, random_state=42)\n",
    "X_val,X_test,y_val,y_test=train_test_split(X_test,y_test, test_size=0.5,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49131aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 9) (160, 5)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a106d976",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self,A,B):\n",
    "        self.X=torch.tensor(A,dtype=torch.float32)\n",
    "        self.Y=torch.tensor(B,dtype=torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index],self.Y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e3e793f",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataset=dataset(A=X_train,B=y_train)\n",
    "valdataset=dataset(A=X_val,B=y_val)\n",
    "testdataset=dataset(A=X_test,B=y_test)\n",
    "\n",
    "traindata_laoder= DataLoader(traindataset, batch_size= 10, shuffle=True)\n",
    "testdata_loader= DataLoader(testdataset, batch_size= 10,shuffle=True)\n",
    "valdata_loader=DataLoader(valdataset,batch_size= 10,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "65d644e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classification,self).__init__()\n",
    "        self.Linear1=nn.Linear(X.shape[1],10)\n",
    "        self.Linear2=nn.Linear(10,Y.shape[1])\n",
    "            \n",
    "    def forward(self,x):\n",
    "        x=self.Linear1(x)\n",
    "        x=self.Linear2(x)\n",
    "        return x\n",
    "model=Classification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b670a49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                   [-1, 10]             100\n",
      "            Linear-2                    [-1, 5]              55\n",
      "================================================================\n",
      "Total params: 155\n",
      "Trainable params: 155\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model,input_size=(xarray.shape[1],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa4367bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "critetion=nn.CrossEntropyLoss()\n",
    "optimizer=optim.Adam(model.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b14e5115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1\n",
      "          \n",
      "          train_loss:3.048769064247608 ,train_accuracy47.5\n",
      "          val_loss: 2.9203635454177856 ,val_accuracy: 35.0\n",
      "====================\n",
      "Epoch:2\n",
      "          \n",
      "          train_loss:1.9143274277448654 ,train_accuracy48.75\n",
      "          val_loss: 1.7374166250228882 ,val_accuracy: 35.0\n",
      "====================\n",
      "Epoch:3\n",
      "          \n",
      "          train_loss:1.1934584453701973 ,train_accuracy53.125\n",
      "          val_loss: 1.1715489625930786 ,val_accuracy: 50.0\n",
      "====================\n",
      "Epoch:4\n",
      "          \n",
      "          train_loss:1.0231591165065765 ,train_accuracy61.25000000000001\n",
      "          val_loss: 1.1581799387931824 ,val_accuracy: 50.0\n",
      "====================\n",
      "Epoch:5\n",
      "          \n",
      "          train_loss:1.0053367912769318 ,train_accuracy60.0\n",
      "          val_loss: 1.1746883988380432 ,val_accuracy: 50.0\n",
      "====================\n",
      "Epoch:6\n",
      "          \n",
      "          train_loss:0.9850547760725021 ,train_accuracy60.62499999999999\n",
      "          val_loss: 1.1359978020191193 ,val_accuracy: 50.0\n",
      "====================\n",
      "Epoch:7\n",
      "          \n",
      "          train_loss:0.969492930918932 ,train_accuracy60.0\n",
      "          val_loss: 1.1277180314064026 ,val_accuracy: 50.0\n",
      "====================\n",
      "Epoch:8\n",
      "          \n",
      "          train_loss:0.9623364210128784 ,train_accuracy60.62499999999999\n",
      "          val_loss: 1.1028006672859192 ,val_accuracy: 50.0\n",
      "====================\n",
      "Epoch:9\n",
      "          \n",
      "          train_loss:0.9430075734853745 ,train_accuracy61.25000000000001\n",
      "          val_loss: 1.096888244152069 ,val_accuracy: 50.0\n",
      "====================\n",
      "Epoch:10\n",
      "          \n",
      "          train_loss:0.9332581795752048 ,train_accuracy60.62499999999999\n",
      "          val_loss: 1.0884120464324951 ,val_accuracy: 50.0\n",
      "====================\n",
      "Epoch:11\n",
      "          \n",
      "          train_loss:0.9233338609337807 ,train_accuracy61.875\n",
      "          val_loss: 1.059516191482544 ,val_accuracy: 50.0\n",
      "====================\n",
      "Epoch:12\n",
      "          \n",
      "          train_loss:0.912509523332119 ,train_accuracy61.875\n",
      "          val_loss: 1.0715234875679016 ,val_accuracy: 50.0\n",
      "====================\n",
      "Epoch:13\n",
      "          \n",
      "          train_loss:0.9011529125273228 ,train_accuracy60.62499999999999\n",
      "          val_loss: 1.0395990014076233 ,val_accuracy: 50.0\n",
      "====================\n",
      "Epoch:14\n",
      "          \n",
      "          train_loss:0.8876664862036705 ,train_accuracy61.875\n",
      "          val_loss: 1.0438151061534882 ,val_accuracy: 50.0\n",
      "====================\n",
      "Epoch:15\n",
      "          \n",
      "          train_loss:0.8834374845027924 ,train_accuracy64.375\n",
      "          val_loss: 1.0395108759403229 ,val_accuracy: 50.0\n",
      "====================\n",
      "Epoch:16\n",
      "          \n",
      "          train_loss:0.8739229179918766 ,train_accuracy61.25000000000001\n",
      "          val_loss: 1.043266773223877 ,val_accuracy: 50.0\n",
      "====================\n",
      "Epoch:17\n",
      "          \n",
      "          train_loss:0.8780884761363268 ,train_accuracy61.875\n",
      "          val_loss: 0.9998374581336975 ,val_accuracy: 50.0\n",
      "====================\n",
      "Epoch:18\n",
      "          \n",
      "          train_loss:0.855231337249279 ,train_accuracy61.875\n",
      "          val_loss: 1.0208971500396729 ,val_accuracy: 50.0\n",
      "====================\n",
      "Epoch:19\n",
      "          \n",
      "          train_loss:0.8532304689288139 ,train_accuracy63.74999999999999\n",
      "          val_loss: 0.9997309446334839 ,val_accuracy: 50.0\n",
      "====================\n",
      "Epoch:20\n",
      "          \n",
      "          train_loss:0.8340368680655956 ,train_accuracy64.375\n",
      "          val_loss: 1.0003403425216675 ,val_accuracy: 45.0\n",
      "====================\n",
      "Epoch:21\n",
      "          \n",
      "          train_loss:0.8333361949771643 ,train_accuracy67.5\n",
      "          val_loss: 0.9872580170631409 ,val_accuracy: 50.0\n",
      "====================\n",
      "Epoch:22\n",
      "          \n",
      "          train_loss:0.8276040572673082 ,train_accuracy64.375\n",
      "          val_loss: 0.9640155732631683 ,val_accuracy: 50.0\n",
      "====================\n",
      "Epoch:23\n",
      "          \n",
      "          train_loss:0.8205587044358253 ,train_accuracy65.0\n",
      "          val_loss: 0.9754070043563843 ,val_accuracy: 50.0\n",
      "====================\n",
      "Epoch:24\n",
      "          \n",
      "          train_loss:0.8074853923171759 ,train_accuracy66.25\n",
      "          val_loss: 0.9868262112140656 ,val_accuracy: 55.00000000000001\n",
      "====================\n",
      "Epoch:25\n",
      "          \n",
      "          train_loss:0.8010024540126324 ,train_accuracy72.5\n",
      "          val_loss: 0.946567714214325 ,val_accuracy: 50.0\n",
      "====================\n",
      "Epoch:26\n",
      "          \n",
      "          train_loss:0.7847925405949354 ,train_accuracy66.875\n",
      "          val_loss: 0.9414413273334503 ,val_accuracy: 50.0\n",
      "====================\n",
      "Epoch:27\n",
      "          \n",
      "          train_loss:0.7868385724723339 ,train_accuracy65.625\n",
      "          val_loss: 0.9243717193603516 ,val_accuracy: 55.00000000000001\n",
      "====================\n",
      "Epoch:28\n",
      "          \n",
      "          train_loss:0.7722826730459929 ,train_accuracy71.875\n",
      "          val_loss: 0.922942191362381 ,val_accuracy: 65.0\n",
      "====================\n",
      "Epoch:29\n",
      "          \n",
      "          train_loss:0.7644360698759556 ,train_accuracy70.625\n",
      "          val_loss: 0.9318794310092926 ,val_accuracy: 50.0\n",
      "====================\n",
      "Epoch:30\n",
      "          \n",
      "          train_loss:0.7555228229612112 ,train_accuracy67.5\n",
      "          val_loss: 0.9029023051261902 ,val_accuracy: 55.00000000000001\n",
      "====================\n",
      "Epoch:31\n",
      "          \n",
      "          train_loss:0.7521702218800783 ,train_accuracy70.625\n",
      "          val_loss: 0.9083625674247742 ,val_accuracy: 60.0\n",
      "====================\n",
      "Epoch:32\n",
      "          \n",
      "          train_loss:0.7442796248942614 ,train_accuracy73.75\n",
      "          val_loss: 0.9015471935272217 ,val_accuracy: 65.0\n",
      "====================\n",
      "Epoch:33\n",
      "          \n",
      "          train_loss:0.7379115764051676 ,train_accuracy72.5\n",
      "          val_loss: 0.887017160654068 ,val_accuracy: 60.0\n",
      "====================\n",
      "Epoch:34\n",
      "          \n",
      "          train_loss:0.7230495624244213 ,train_accuracy72.5\n",
      "          val_loss: 0.8667674660682678 ,val_accuracy: 60.0\n",
      "====================\n",
      "Epoch:35\n",
      "          \n",
      "          train_loss:0.7193088978528976 ,train_accuracy72.5\n",
      "          val_loss: 0.8853312432765961 ,val_accuracy: 60.0\n",
      "====================\n",
      "Epoch:36\n",
      "          \n",
      "          train_loss:0.710366940125823 ,train_accuracy75.0\n",
      "          val_loss: 0.8497586846351624 ,val_accuracy: 65.0\n",
      "====================\n",
      "Epoch:37\n",
      "          \n",
      "          train_loss:0.70401506498456 ,train_accuracy73.75\n",
      "          val_loss: 0.8931751251220703 ,val_accuracy: 60.0\n",
      "====================\n",
      "Epoch:38\n",
      "          \n",
      "          train_loss:0.6979403961449862 ,train_accuracy76.25\n",
      "          val_loss: 0.8440758883953094 ,val_accuracy: 60.0\n",
      "====================\n",
      "Epoch:39\n",
      "          \n",
      "          train_loss:0.6806430369615555 ,train_accuracy74.375\n",
      "          val_loss: 0.8388210535049438 ,val_accuracy: 65.0\n",
      "====================\n",
      "Epoch:40\n",
      "          \n",
      "          train_loss:0.6747671831399202 ,train_accuracy75.625\n",
      "          val_loss: 0.8356564939022064 ,val_accuracy: 60.0\n",
      "====================\n",
      "Epoch:41\n",
      "          \n",
      "          train_loss:0.6660087928175926 ,train_accuracy77.5\n",
      "          val_loss: 0.8100974261760712 ,val_accuracy: 65.0\n",
      "====================\n",
      "Epoch:42\n",
      "          \n",
      "          train_loss:0.6556759271770716 ,train_accuracy76.25\n",
      "          val_loss: 0.8134466111660004 ,val_accuracy: 65.0\n",
      "====================\n",
      "Epoch:43\n",
      "          \n",
      "          train_loss:0.6522039659321308 ,train_accuracy79.375\n",
      "          val_loss: 0.7979632318019867 ,val_accuracy: 65.0\n",
      "====================\n",
      "Epoch:44\n",
      "          \n",
      "          train_loss:0.6413219962269068 ,train_accuracy77.5\n",
      "          val_loss: 0.8059751689434052 ,val_accuracy: 60.0\n",
      "====================\n",
      "Epoch:45\n",
      "          \n",
      "          train_loss:0.6372355595231056 ,train_accuracy76.875\n",
      "          val_loss: 0.7895870506763458 ,val_accuracy: 65.0\n",
      "====================\n",
      "Epoch:46\n",
      "          \n",
      "          train_loss:0.6328289527446032 ,train_accuracy80.0\n",
      "          val_loss: 0.8101973533630371 ,val_accuracy: 60.0\n",
      "====================\n",
      "Epoch:47\n",
      "          \n",
      "          train_loss:0.6198305655270815 ,train_accuracy79.375\n",
      "          val_loss: 0.7574596405029297 ,val_accuracy: 70.0\n",
      "====================\n",
      "Epoch:48\n",
      "          \n",
      "          train_loss:0.6231278907507658 ,train_accuracy77.5\n",
      "          val_loss: 0.7700286507606506 ,val_accuracy: 65.0\n",
      "====================\n",
      "Epoch:49\n",
      "          \n",
      "          train_loss:0.6048476733267307 ,train_accuracy81.25\n",
      "          val_loss: 0.7797234356403351 ,val_accuracy: 60.0\n",
      "====================\n",
      "Epoch:50\n",
      "          \n",
      "          train_loss:0.5965212471783161 ,train_accuracy84.375\n",
      "          val_loss: 0.7375563681125641 ,val_accuracy: 65.0\n",
      "====================\n",
      "Epoch:51\n",
      "          \n",
      "          train_loss:0.5947027653455734 ,train_accuracy81.25\n",
      "          val_loss: 0.7228206098079681 ,val_accuracy: 70.0\n",
      "====================\n",
      "Epoch:52\n",
      "          \n",
      "          train_loss:0.5877551399171352 ,train_accuracy81.875\n",
      "          val_loss: 0.7495932579040527 ,val_accuracy: 65.0\n",
      "====================\n",
      "Epoch:53\n",
      "          \n",
      "          train_loss:0.5774135384708643 ,train_accuracy81.875\n",
      "          val_loss: 0.73758465051651 ,val_accuracy: 60.0\n",
      "====================\n",
      "Epoch:54\n",
      "          \n",
      "          train_loss:0.5698461104184389 ,train_accuracy82.5\n",
      "          val_loss: 0.7081295847892761 ,val_accuracy: 70.0\n",
      "====================\n",
      "Epoch:55\n",
      "          \n",
      "          train_loss:0.56384033896029 ,train_accuracy82.5\n",
      "          val_loss: 0.7153415083885193 ,val_accuracy: 65.0\n",
      "====================\n",
      "Epoch:56\n",
      "          \n",
      "          train_loss:0.5712305996567011 ,train_accuracy81.25\n",
      "          val_loss: 0.6989426016807556 ,val_accuracy: 65.0\n",
      "====================\n",
      "Epoch:57\n",
      "          \n",
      "          train_loss:0.5504566710442305 ,train_accuracy82.5\n",
      "          val_loss: 0.7271689474582672 ,val_accuracy: 65.0\n",
      "====================\n",
      "Epoch:58\n",
      "          \n",
      "          train_loss:0.5439767669886351 ,train_accuracy84.375\n",
      "          val_loss: 0.6612949371337891 ,val_accuracy: 70.0\n",
      "====================\n",
      "Epoch:59\n",
      "          \n",
      "          train_loss:0.5349271968007088 ,train_accuracy85.625\n",
      "          val_loss: 0.6835412085056305 ,val_accuracy: 65.0\n",
      "====================\n",
      "Epoch:60\n",
      "          \n",
      "          train_loss:0.5271466290578246 ,train_accuracy81.875\n",
      "          val_loss: 0.6479013711214066 ,val_accuracy: 70.0\n",
      "====================\n",
      "Epoch:61\n",
      "          \n",
      "          train_loss:0.5232389699667692 ,train_accuracy85.625\n",
      "          val_loss: 0.6638983488082886 ,val_accuracy: 65.0\n",
      "====================\n",
      "Epoch:62\n",
      "          \n",
      "          train_loss:0.5140991043299437 ,train_accuracy84.375\n",
      "          val_loss: 0.640772670507431 ,val_accuracy: 70.0\n",
      "====================\n",
      "Epoch:63\n",
      "          \n",
      "          train_loss:0.5118936449289322 ,train_accuracy82.5\n",
      "          val_loss: 0.6518579423427582 ,val_accuracy: 60.0\n",
      "====================\n",
      "Epoch:64\n",
      "          \n",
      "          train_loss:0.5073019713163376 ,train_accuracy88.75\n",
      "          val_loss: 0.6523666381835938 ,val_accuracy: 70.0\n",
      "====================\n",
      "Epoch:65\n",
      "          \n",
      "          train_loss:0.5025518983602524 ,train_accuracy85.0\n",
      "          val_loss: 0.6307366788387299 ,val_accuracy: 70.0\n",
      "====================\n",
      "Epoch:66\n",
      "          \n",
      "          train_loss:0.48801840748637915 ,train_accuracy86.25\n",
      "          val_loss: 0.6318195462226868 ,val_accuracy: 70.0\n",
      "====================\n",
      "Epoch:67\n",
      "          \n",
      "          train_loss:0.4798910040408373 ,train_accuracy86.875\n",
      "          val_loss: 0.6108420193195343 ,val_accuracy: 70.0\n",
      "====================\n",
      "Epoch:68\n",
      "          \n",
      "          train_loss:0.4802350541576743 ,train_accuracy86.25\n",
      "          val_loss: 0.6007887125015259 ,val_accuracy: 70.0\n",
      "====================\n",
      "Epoch:69\n",
      "          \n",
      "          train_loss:0.469762759283185 ,train_accuracy87.5\n",
      "          val_loss: 0.6202988624572754 ,val_accuracy: 75.0\n",
      "====================\n",
      "Epoch:70\n",
      "          \n",
      "          train_loss:0.47119421511888504 ,train_accuracy85.625\n",
      "          val_loss: 0.5758615732192993 ,val_accuracy: 75.0\n",
      "====================\n",
      "Epoch:71\n",
      "          \n",
      "          train_loss:0.4631631737574935 ,train_accuracy85.625\n",
      "          val_loss: 0.598157674074173 ,val_accuracy: 70.0\n",
      "====================\n",
      "Epoch:72\n",
      "          \n",
      "          train_loss:0.45513700507581234 ,train_accuracy86.25\n",
      "          val_loss: 0.5751073956489563 ,val_accuracy: 85.0\n",
      "====================\n",
      "Epoch:73\n",
      "          \n",
      "          train_loss:0.44874183367937803 ,train_accuracy86.875\n",
      "          val_loss: 0.5793495178222656 ,val_accuracy: 75.0\n",
      "====================\n",
      "Epoch:74\n",
      "          \n",
      "          train_loss:0.44323505088686943 ,train_accuracy86.25\n",
      "          val_loss: 0.5484797805547714 ,val_accuracy: 90.0\n",
      "====================\n",
      "Epoch:75\n",
      "          \n",
      "          train_loss:0.44071128219366074 ,train_accuracy89.375\n",
      "          val_loss: 0.5636820495128632 ,val_accuracy: 75.0\n",
      "====================\n",
      "Epoch:76\n",
      "          \n",
      "          train_loss:0.4341169586405158 ,train_accuracy86.875\n",
      "          val_loss: 0.534637376666069 ,val_accuracy: 90.0\n",
      "====================\n",
      "Epoch:77\n",
      "          \n",
      "          train_loss:0.42401587031781673 ,train_accuracy89.375\n",
      "          val_loss: 0.5692058354616165 ,val_accuracy: 75.0\n",
      "====================\n",
      "Epoch:78\n",
      "          \n",
      "          train_loss:0.4225206784904003 ,train_accuracy90.0\n",
      "          val_loss: 0.5301401019096375 ,val_accuracy: 90.0\n",
      "====================\n",
      "Epoch:79\n",
      "          \n",
      "          train_loss:0.41871528699994087 ,train_accuracy89.375\n",
      "          val_loss: 0.5289441794157028 ,val_accuracy: 95.0\n",
      "====================\n",
      "Epoch:80\n",
      "          \n",
      "          train_loss:0.4140364611521363 ,train_accuracy86.875\n",
      "          val_loss: 0.533290445804596 ,val_accuracy: 95.0\n",
      "====================\n",
      "Epoch:81\n",
      "          \n",
      "          train_loss:0.4118184670805931 ,train_accuracy89.375\n",
      "          val_loss: 0.5344449877738953 ,val_accuracy: 85.0\n",
      "====================\n",
      "Epoch:82\n",
      "          \n",
      "          train_loss:0.4016038849949837 ,train_accuracy89.375\n",
      "          val_loss: 0.5061743557453156 ,val_accuracy: 95.0\n",
      "====================\n",
      "Epoch:83\n",
      "          \n",
      "          train_loss:0.3971865139901638 ,train_accuracy90.625\n",
      "          val_loss: 0.4967189431190491 ,val_accuracy: 95.0\n",
      "====================\n",
      "Epoch:84\n",
      "          \n",
      "          train_loss:0.3951445994898677 ,train_accuracy90.0\n",
      "          val_loss: 0.4995071738958359 ,val_accuracy: 95.0\n",
      "====================\n",
      "Epoch:85\n",
      "          \n",
      "          train_loss:0.3875862807035446 ,train_accuracy88.75\n",
      "          val_loss: 0.501709058880806 ,val_accuracy: 95.0\n",
      "====================\n",
      "Epoch:86\n",
      "          \n",
      "          train_loss:0.38094114046543837 ,train_accuracy90.0\n",
      "          val_loss: 0.4834599643945694 ,val_accuracy: 95.0\n",
      "====================\n",
      "Epoch:87\n",
      "          \n",
      "          train_loss:0.3818596815690398 ,train_accuracy89.375\n",
      "          val_loss: 0.4774005562067032 ,val_accuracy: 95.0\n",
      "====================\n",
      "Epoch:88\n",
      "          \n",
      "          train_loss:0.37860496900975704 ,train_accuracy89.375\n",
      "          val_loss: 0.48056796193122864 ,val_accuracy: 95.0\n",
      "====================\n",
      "Epoch:89\n",
      "          \n",
      "          train_loss:0.38086170703172684 ,train_accuracy88.75\n",
      "          val_loss: 0.4924951642751694 ,val_accuracy: 90.0\n",
      "====================\n",
      "Epoch:90\n",
      "          \n",
      "          train_loss:0.37330333795398474 ,train_accuracy88.75\n",
      "          val_loss: 0.45753659307956696 ,val_accuracy: 95.0\n",
      "====================\n",
      "Epoch:91\n",
      "          \n",
      "          train_loss:0.37073505483567715 ,train_accuracy92.5\n",
      "          val_loss: 0.45910051465034485 ,val_accuracy: 95.0\n",
      "====================\n",
      "Epoch:92\n",
      "          \n",
      "          train_loss:0.36471153795719147 ,train_accuracy89.375\n",
      "          val_loss: 0.44305625557899475 ,val_accuracy: 95.0\n",
      "====================\n",
      "Epoch:93\n",
      "          \n",
      "          train_loss:0.3619648525491357 ,train_accuracy93.75\n",
      "          val_loss: 0.46785391867160797 ,val_accuracy: 95.0\n",
      "====================\n",
      "Epoch:94\n",
      "          \n",
      "          train_loss:0.35600403510034084 ,train_accuracy91.25\n",
      "          val_loss: 0.4496661424636841 ,val_accuracy: 90.0\n",
      "====================\n",
      "Epoch:95\n",
      "          \n",
      "          train_loss:0.351141270250082 ,train_accuracy91.875\n",
      "          val_loss: 0.46192359924316406 ,val_accuracy: 90.0\n",
      "====================\n",
      "Epoch:96\n",
      "          \n",
      "          train_loss:0.3527757814154029 ,train_accuracy91.25\n",
      "          val_loss: 0.42175132036209106 ,val_accuracy: 95.0\n",
      "====================\n",
      "Epoch:97\n",
      "          \n",
      "          train_loss:0.34178740670904517 ,train_accuracy91.25\n",
      "          val_loss: 0.42950402200222015 ,val_accuracy: 95.0\n",
      "====================\n",
      "Epoch:98\n",
      "          \n",
      "          train_loss:0.3426747554913163 ,train_accuracy90.625\n",
      "          val_loss: 0.42656296491622925 ,val_accuracy: 95.0\n",
      "====================\n",
      "Epoch:99\n",
      "          \n",
      "          train_loss:0.3378531914204359 ,train_accuracy93.125\n",
      "          val_loss: 0.43321481347084045 ,val_accuracy: 95.0\n",
      "====================\n",
      "Epoch:100\n",
      "          \n",
      "          train_loss:0.3313099071383476 ,train_accuracy91.25\n",
      "          val_loss: 0.42465610802173615 ,val_accuracy: 95.0\n",
      "====================\n",
      "Epoch:101\n",
      "          \n",
      "          train_loss:0.3280634470283985 ,train_accuracy92.5\n",
      "          val_loss: 0.4102306663990021 ,val_accuracy: 95.0\n",
      "====================\n",
      "Epoch:102\n",
      "          \n",
      "          train_loss:0.32828336022794247 ,train_accuracy91.25\n",
      "          val_loss: 0.39789389073848724 ,val_accuracy: 95.0\n",
      "====================\n",
      "Epoch:103\n",
      "          \n",
      "          train_loss:0.3242505150847137 ,train_accuracy91.25\n",
      "          val_loss: 0.4006515294313431 ,val_accuracy: 95.0\n",
      "====================\n",
      "Epoch:104\n",
      "          \n",
      "          train_loss:0.3265229891985655 ,train_accuracy91.875\n",
      "          val_loss: 0.39103128015995026 ,val_accuracy: 95.0\n",
      "====================\n",
      "Epoch:105\n",
      "          \n",
      "          train_loss:0.3166405758820474 ,train_accuracy92.5\n",
      "          val_loss: 0.38907165825366974 ,val_accuracy: 95.0\n",
      "====================\n",
      "Epoch:106\n",
      "          \n",
      "          train_loss:0.3135844636708498 ,train_accuracy92.5\n",
      "          val_loss: 0.3865983784198761 ,val_accuracy: 95.0\n",
      "====================\n",
      "Epoch:107\n",
      "          \n",
      "          train_loss:0.30667746160179377 ,train_accuracy91.875\n",
      "          val_loss: 0.3940969556570053 ,val_accuracy: 95.0\n",
      "====================\n",
      "Epoch:108\n",
      "          \n",
      "          train_loss:0.30670830281451344 ,train_accuracy91.875\n",
      "          val_loss: 0.39534522593021393 ,val_accuracy: 95.0\n",
      "====================\n",
      "Epoch:109\n",
      "          \n",
      "          train_loss:0.3067308822646737 ,train_accuracy91.875\n",
      "          val_loss: 0.36289211362600327 ,val_accuracy: 95.0\n",
      "====================\n",
      "Epoch:110\n",
      "          \n",
      "          train_loss:0.31186340702697635 ,train_accuracy90.0\n",
      "          val_loss: 0.3668263405561447 ,val_accuracy: 95.0\n",
      "====================\n",
      "Epoch:111\n",
      "          \n",
      "          train_loss:0.3026875499635935 ,train_accuracy92.5\n",
      "          val_loss: 0.37952882051467896 ,val_accuracy: 95.0\n",
      "====================\n",
      "Epoch:112\n",
      "          \n",
      "          train_loss:0.2974304377567023 ,train_accuracy92.5\n",
      "          val_loss: 0.36127524077892303 ,val_accuracy: 95.0\n",
      "====================\n",
      "Epoch:113\n",
      "          \n",
      "          train_loss:0.2936247498728335 ,train_accuracy93.75\n",
      "          val_loss: 0.3577814847230911 ,val_accuracy: 95.0\n",
      "====================\n",
      "Epoch:114\n",
      "          \n",
      "          train_loss:0.2940135784447193 ,train_accuracy91.875\n",
      "          val_loss: 0.3503594473004341 ,val_accuracy: 95.0\n",
      "====================\n",
      "Epoch:115\n",
      "          \n",
      "          train_loss:0.28951325826346874 ,train_accuracy92.5\n",
      "          val_loss: 0.36328887939453125 ,val_accuracy: 95.0\n",
      "====================\n",
      "Epoch:116\n",
      "          \n",
      "          train_loss:0.28370277862995863 ,train_accuracy95.0\n",
      "          val_loss: 0.3404301404953003 ,val_accuracy: 95.0\n",
      "====================\n",
      "Epoch:117\n",
      "          \n",
      "          train_loss:0.28284869622439146 ,train_accuracy93.125\n",
      "          val_loss: 0.3537849485874176 ,val_accuracy: 95.0\n",
      "====================\n",
      "Epoch:118\n",
      "          \n",
      "          train_loss:0.2819616161286831 ,train_accuracy93.75\n",
      "          val_loss: 0.33810722827911377 ,val_accuracy: 95.0\n",
      "====================\n",
      "Epoch:119\n",
      "          \n",
      "          train_loss:0.27656237967312336 ,train_accuracy93.125\n",
      "          val_loss: 0.34941428899765015 ,val_accuracy: 95.0\n",
      "====================\n",
      "Epoch:120\n",
      "          \n",
      "          train_loss:0.27648764569312334 ,train_accuracy92.5\n",
      "          val_loss: 0.32816219329833984 ,val_accuracy: 95.0\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(120):\n",
    "    ttloss=0\n",
    "    tacc=0\n",
    "    ttsample=0\n",
    "\n",
    "    vtloss=0\n",
    "    vacc=0\n",
    "    vtsample=0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for value,label in traindata_laoder:\n",
    "        optimizer.zero_grad()\n",
    "        output=model(value)\n",
    "        if label.dim() > 1:\n",
    "            label = torch.argmax(label, dim=1)\n",
    "        # loss\n",
    "        batchloss=critetion(output,label)\n",
    "        ttloss+=batchloss.item()*value.size(0)\n",
    "        # accuracy\n",
    "        _, preds = torch.max(output, 1)\n",
    "        tacc+=(preds == label).sum().item()\n",
    "        ttsample += label.size(0)\n",
    "\n",
    "        batchloss.backward()\n",
    "        optimizer.step()\n",
    "        # optimizer.zero_grad()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for value,label in valdata_loader:\n",
    "            if label.dim() > 1:\n",
    "                label = torch.argmax(label, dim=1)\n",
    "            output=model(value)\n",
    "            # loss\n",
    "            batchloss=critetion(output,label)\n",
    "            vtloss+=batchloss.item()*value.size(0)\n",
    "            # accuracy\n",
    "           \n",
    "            _, preds = torch.max(output, 1)\n",
    "            vacc += (preds == label).sum().item()\n",
    "            vtsample += label.size(0)\n",
    "\n",
    "    tatl = ttloss / len(traindata_laoder.dataset)\n",
    "    ta = (tacc / ttsample)*100 \n",
    "\n",
    "    vatl = vtloss / len(valdata_loader.dataset)\n",
    "    va= (vacc / vtsample)*100\n",
    "\n",
    "    print(f\"\"\"Epoch:{i+1}\n",
    "          \n",
    "          train_loss:{tatl} ,train_accuracy{ta}\n",
    "          val_loss: {vatl} ,val_accuracy: {va}\"\"\")\n",
    "    \n",
    "    print(\"=\"*20)           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a78ac1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss:0.24349480867385864 ,test_accuracy95.0\n"
     ]
    }
   ],
   "source": [
    "teloss=0\n",
    "tesample=0\n",
    "teacc=0\n",
    "with torch.no_grad():\n",
    "        for value,label in testdata_loader:\n",
    "            if label.dim() > 1:\n",
    "                label = torch.argmax(label, dim=1)\n",
    "            output=model(value)\n",
    "            # loss\n",
    "            batchloss=critetion(output,label)\n",
    "            teloss+=batchloss.item()*value.size(0)\n",
    "            # accuracy\n",
    "           \n",
    "            _, preds = torch.max(output, 1)\n",
    "            teacc += (preds == label).sum().item()\n",
    "            tesample += label.size(0)\n",
    "\n",
    "        tetl= average_total_loss = teloss / len(testdata_loader.dataset)\n",
    "        tea= (teacc / tesample)*100\n",
    "\n",
    "        print(f\"test_loss:{tetl} ,test_accuracy{tea}\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
