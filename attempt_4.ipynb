{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMG39kxAJjCPyo1HfWmh1M+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gokul0Krishna/pytorchpractice/blob/master/attempt_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/synthetic.zip\"\n",
        "!unzip \"/content/washer.v1i.multiclass.zip\"\n",
        "!unzip \"/content/test.zip\"\n",
        "!unzip \"/content/washer.v4i.multiclass.zip\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1j0_oikYcjdS",
        "outputId": "f4929eea-4874-4953-ce30-3af8c38ee2d4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open /content/synthetic.zip, /content/synthetic.zip.zip or /content/synthetic.zip.ZIP.\n",
            "unzip:  cannot find or open /content/washer.v1i.multiclass.zip, /content/washer.v1i.multiclass.zip.zip or /content/washer.v1i.multiclass.zip.ZIP.\n",
            "unzip:  cannot find or open /content/test.zip, /content/test.zip.zip or /content/test.zip.ZIP.\n",
            "unzip:  cannot find or open /content/washer.v4i.multiclass.zip, /content/washer.v4i.multiclass.zip.zip or /content/washer.v4i.multiclass.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision import models,transforms\n",
        "from torch.utils.data import DataLoader,Dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "1DCVfnDmckf2",
        "outputId": "97f5a155-5cb9-4ea4-ecad-bb5d5582c6eb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_spec\u001b[0;34m(name, path, target)\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: '_PyDriveImportHook' object has no attribute 'find_spec'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2-3533770158.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# .extensions) before entering _meta_registrations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mextension\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_HAS_OPS\u001b[0m  \u001b[0;31m# usort:skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_meta_registrations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m  \u001b[0;31m# usort:skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdtd\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDTD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0meurosat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEuroSAT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfakedata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFakeData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfer2013\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFER2013\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfgvc_aircraft\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFGVCAircraft\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/fakedata.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVisionDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mautoaugment\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_log_api_usage_once\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_interpolation_modes_from_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInterpolationMode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_log_api_usage_once\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_functional_pil\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_functional_tensor\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/_functional_pil.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageEnhance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageOps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/ImageEnhance.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mannotations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageFilter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageStat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_spec\u001b[0;34m(name, path, target)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_spec_legacy\u001b[0;34m(finder, name, path)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l=['washer','nut']\n",
        "realimages=[]\n",
        "reallabels=[]\n",
        "for i in os.listdir(\"/content/washer.v4i.multiclass\"):\n",
        "  for j in os.listdir(\"/content/washer.v4i.multiclass/\"+i):\n",
        "    if j.endswith(\".jpg\") == True:\n",
        "      realimages.append(\"/content/washer.v4i.multiclass/\"+i+\"/\"+j)\n",
        "      reallabels.append(\"washer\")\n",
        "\n",
        "for i in os.listdir(\"/content/washer.v1i.multiclass\"):\n",
        "    if i.endswith(\".txt\") == False:\n",
        "      for j in os.listdir(\"/content/washer.v1i.multiclass/\"+i):\n",
        "        if j.endswith(\".jpg\") == True:\n",
        "          realimages.append(\"/content/washer.v1i.multiclass/\"+i+\"/\"+j)\n",
        "          reallabels.append(\"washer\")\n",
        "a=0\n",
        "for i in os.listdir(\"/content/test\"):\n",
        "  for j in os.listdir(\"/content/test/\"+i):\n",
        "      if a>250:\n",
        "          break\n",
        "      realimages.append(\"/content/test/\"+i+\"/\"+j)\n",
        "      reallabels.append(\"nut\")\n",
        "      a+=1"
      ],
      "metadata": {
        "id": "WjwGIqmZcxcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "syntheticimages=[]\n",
        "syntheticlabels=[]\n",
        "for i in os.listdir(\"/content/synthetic\"):\n",
        "  for j in os.listdir(\"/content/synthetic/\"+i):\n",
        "      syntheticimages.append(\"/content/synthetic/\"+i+\"/\"+j)\n",
        "      syntheticlabels.append(i)"
      ],
      "metadata": {
        "id": "qlLZz4xudCIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfs=pd.DataFrame({'X':syntheticimages,'Y':syntheticlabels})\n",
        "dfs=pd.get_dummies(dfs,columns=['Y'],dtype=float)\n",
        "dfs.columns = dfs.columns.str.replace(\"Y_\", \"\")\n",
        "\n",
        "dfr=pd.DataFrame({'X':realimages,'Y':reallabels})\n",
        "dfr=pd.get_dummies(dfr,columns=['Y'],dtype=float)\n",
        "dfr.columns = dfr.columns.str.replace(\"Y_\", \"\")"
      ],
      "metadata": {
        "id": "LR3v_bbhdMwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class customdataset(Dataset):\n",
        "    def __init__(self,x,y,transform=None):\n",
        "        self.x=x\n",
        "        self.y=y\n",
        "        self.transform=transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.x.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        imgpath=self.x.iloc[index]\n",
        "        if self.transform:\n",
        "            image=Image.open(imgpath).convert(\"RGB\")\n",
        "            image=self.transform(image)\n",
        "        label_row = self.y.iloc[index, 0:2]\n",
        "        label_tensor = torch.tensor(label_row.values.astype(np.float32))\n",
        "        label_index = torch.argmax(label_tensor).item()\n",
        "\n",
        "        return image,label_index"
      ],
      "metadata": {
        "id": "2MeSibmVdTXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "synthetic_train_transforms = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomCrop(224),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.2),\n",
        "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n",
        "    transforms.RandomRotation(30),\n",
        "    transforms.RandomPerspective(distortion_scale=0.2, p=0.5),\n",
        "    transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n"
      ],
      "metadata": {
        "id": "hmDbLpbodrH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testmodel = models.densenet201(pretrained=False)"
      ],
      "metadata": {
        "id": "ECbQ8Gnydrw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "xstrain, xstest,ystrain,ystest = train_test_split(dfs['X'],dfs[l],random_state=42, test_size=0.2)\n",
        "traindataset=customdataset(x=xstrain,y=ystrain,transform=synthetic_train_transforms)\n",
        "valdataset=customdataset(x=xstest,y=ystest,transform=synthetic_train_transforms)\n",
        "\n",
        "trainloader=DataLoader(traindataset,batch_size=32,shuffle=True)\n",
        "valloader=DataLoader(valdataset,batch_size=32,shuffle=True)"
      ],
      "metadata": {
        "id": "nSYKUnV60Dhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testmodel.classifier = torch.nn.Linear(testmodel.classifier.in_features, 2)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(testmodel.parameters(), lr=0.0001)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "testmodel = testmodel.to(device)"
      ],
      "metadata": {
        "id": "qnxJ_iMi0DE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 3\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    testmodel.train()\n",
        "    trunningloss,vrunningloss=0.0,0.0\n",
        "    ttotal,vtotal = 0,0\n",
        "    tacc,vacc=0.0,0.0\n",
        "    for inputs, labels in trainloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = testmodel(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        trunningloss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)  # Get predicted class\n",
        "        ttotal += labels.size(0)\n",
        "        tacc += (predicted == labels).sum().item()\n",
        "\n",
        "\n",
        "    testmodel.eval()\n",
        "    with torch.no_grad():\n",
        "      for inputs, labels in valloader:\n",
        "          inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "          outputs = testmodel(inputs)\n",
        "          loss = criterion(outputs, labels)\n",
        "          vrunningloss += loss.item()\n",
        "\n",
        "          _, predicted = torch.max(outputs.data, 1)  # Get predicted class\n",
        "          vtotal += labels.size(0)\n",
        "          vacc += (predicted == labels).sum().item()\n",
        "\n",
        "    print(\"=\"*20)\n",
        "    print(f\"\"\"Epoch {epoch+1}\n",
        "          train\n",
        "          Loss: {trunningloss/len(trainloader)}\n",
        "          Accuracy: {tacc*100/ttotal}\n",
        "          val\n",
        "          Loss: {vrunningloss/len(valloader)}\n",
        "          Accuracy: {vacc*100/vtotal}\n",
        "          \"\"\")"
      ],
      "metadata": {
        "id": "oLPzLjA_49Y6",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xstrain, xstest,ystrain,ystest = train_test_split(dfs['X'],dfs[l],random_state=42, test_size=0.3)\n",
        "straindataset=customdataset(x=xstrain,y=ystrain,transform=synthetic_train_transforms)\n",
        "svaldataset=customdataset(x=xstest,y=ystest,transform=synthetic_train_transforms)\n",
        "\n",
        "xrtrain, xrtest,yrtrain,yrtest = train_test_split(dfr['X'],dfr[l],random_state=42, test_size=0.3)\n",
        "rtraindataset=customdataset(x=xstrain,y=ystrain,transform=synthetic_train_transforms)\n",
        "rvaldataset=customdataset(x=xstest,y=ystest,transform=synthetic_train_transforms)\n"
      ],
      "metadata": {
        "id": "9A8V3KVD4n7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mixedtraindataset = torch.utils.data.ConcatDataset([straindataset, rtraindataset])\n",
        "# mixedtrainloader = DataLoader(mixedtraindataset, batch_size=64, shuffle=True)\n",
        "\n",
        "mixedvaldataset = torch.utils.data.ConcatDataset([svaldataset, rvaldataset])\n",
        "# mixedvalloader = DataLoader(mixedvaldataset, batch_size=64, shuffle=True)\n"
      ],
      "metadata": {
        "id": "7vVVMM-Y-iwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_weight = 3.0  # Higher weight for real data\n",
        "synthetic_weight = 1.0\n",
        "weights = torch.tensor([synthetic_weight] * len(straindataset) + [real_weight] * len(rtraindataset))\n",
        "sampler = torch.utils.data.WeightedRandomSampler(weights, len(weights))\n",
        "tweighted_mixed_loader = DataLoader(mixedtraindataset, batch_size=32, sampler=sampler)\n",
        "\n",
        "weights = torch.tensor([synthetic_weight] * len(svaldataset) + [real_weight] * len(rvaldataset))\n",
        "sampler = torch.utils.data.WeightedRandomSampler(weights, len(weights))\n",
        "vweighted_mixed_loader = DataLoader(mixedvaldataset, batch_size=32, sampler=sampler)"
      ],
      "metadata": {
        "id": "zx9ybZo-_AfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param in testmodel.features.parameters():\n",
        "    param.requires_grad = False\n",
        "class_weights = torch.tensor([1.0, 3.0])\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
        "optimizer = torch.optim.Adam(testmodel.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "id": "T9U5TZpKChqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 4\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    testmodel.train()\n",
        "    trunningloss,vrunningloss=0.0,0.0\n",
        "    ttotal,vtotal = 0,0\n",
        "    tacc,vacc=0.0,0.0\n",
        "    for inputs, labels in tweighted_mixed_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = testmodel(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        trunningloss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)  # Get predicted class\n",
        "        ttotal += labels.size(0)\n",
        "        tacc += (predicted == labels).sum().item()\n",
        "\n",
        "\n",
        "    testmodel.eval()\n",
        "    with torch.no_grad():\n",
        "      for inputs, labels in vweighted_mixed_loader:\n",
        "          inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "          outputs = testmodel(inputs)\n",
        "          loss = criterion(outputs, labels)\n",
        "          vrunningloss += loss.item()\n",
        "\n",
        "          _, predicted = torch.max(outputs.data, 1)  # Get predicted class\n",
        "          vtotal += labels.size(0)\n",
        "          vacc += (predicted == labels).sum().item()\n",
        "\n",
        "    print(\"=\"*20)\n",
        "    print(f\"\"\"Epoch {epoch+1}\n",
        "          train\n",
        "          Loss: {trunningloss/len(tweighted_mixed_loader)}\n",
        "          Accuracy: {tacc*100/ttotal}\n",
        "          val\n",
        "          Loss: {vrunningloss/len(vweighted_mixed_loader)}\n",
        "          Accuracy: {vacc*100/vtotal}\n",
        "          \"\"\")"
      ],
      "metadata": {
        "id": "lDsKcrb1DOPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_train_transforms = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomCrop(224),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ColorJitter(brightness=0.3, contrast=0.3),\n",
        "    transforms.GaussianBlur(kernel_size=3),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "metadata": {
        "id": "6nGUqT67EeJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rtraindataset=customdataset(x=xstrain,y=ystrain,transform=real_train_transforms)\n",
        "rvaldataset=customdataset(x=xstest,y=ystest,transform=real_train_transforms)\n",
        "mixedtrainloader = DataLoader(mixedtraindataset, batch_size=16, shuffle=True)\n",
        "mixedvalloader = DataLoader(mixedvaldataset, batch_size=16, shuffle=True)"
      ],
      "metadata": {
        "id": "Aok1-uyZFCXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param in testmodel.parameters():\n",
        "    param.requires_grad = True\n",
        "optimizer = torch.optim.Adam(testmodel.parameters(), lr=0.00001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "r5RRR1uSH-O4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 4\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    testmodel.train()\n",
        "    trunningloss,vrunningloss=0.0,0.0\n",
        "    ttotal,vtotal = 0,0\n",
        "    tacc,vacc=0.0,0.0\n",
        "    for inputs, labels in mixedtrainloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = testmodel(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        trunningloss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)  # Get predicted class\n",
        "        ttotal += labels.size(0)\n",
        "        tacc += (predicted == labels).sum().item()\n",
        "\n",
        "\n",
        "    testmodel.eval()\n",
        "    with torch.no_grad():\n",
        "      for inputs, labels in mixedvalloader:\n",
        "          inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "          outputs = testmodel(inputs)\n",
        "          loss = criterion(outputs, labels)\n",
        "          vrunningloss += loss.item()\n",
        "\n",
        "          _, predicted = torch.max(outputs.data, 1)  # Get predicted class\n",
        "          vtotal += labels.size(0)\n",
        "          vacc += (predicted == labels).sum().item()\n",
        "\n",
        "    print(\"=\"*20)\n",
        "    print(f\"\"\"Epoch {epoch+1}\n",
        "          train\n",
        "          Loss: {trunningloss/len(tweighted_mixed_loader)}\n",
        "          Accuracy: {tacc*100/ttotal}\n",
        "          val\n",
        "          Loss: {vrunningloss/len(vweighted_mixed_loader)}\n",
        "          Accuracy: {vacc*100/vtotal}\n",
        "          \"\"\")"
      ],
      "metadata": {
        "id": "V7lumwVsIQoY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}