{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3JP63NHCNSqWVOv9geBel",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gokul0Krishna/pytorchpractice/blob/master/3rdattempt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQ7hzsb3uUi_",
        "outputId": "06eee6a4-0a35-41ac-fa8b-d8a26be2de31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open /content/nuttest.zip, /content/nuttest.zip.zip or /content/nuttest.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "!unzip \"/content/synthetic.zip\"\n",
        "!unzip \"/content/washer.v1i.multiclass.zip\"\n",
        "!unzip \"/content/test.zip\"\n",
        "!unzip \"/content/washer.v4i.multiclass.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import models\n",
        "from torch.utils.data import DataLoader,Dataset"
      ],
      "metadata": {
        "id": "aoIZalMrz2Zb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "l=['washer','nut']\n",
        "realimages=[]\n",
        "reallabels=[]\n",
        "for i in os.listdir(\"/content/washer.v4i.multiclass\"):\n",
        "  for j in os.listdir(\"/content/washer.v4i.multiclass/\"+i):\n",
        "    if j.endswith(\".jpg\") == True:\n",
        "      realimages.append(\"/content/washer.v4i.multiclass/\"+i+\"/\"+j)\n",
        "      reallabels.append(\"washer\")\n",
        "\n",
        "for i in os.listdir(\"/content/washer.v1i.multiclass\"):\n",
        "    if i.endswith(\".txt\") == False:\n",
        "      for j in os.listdir(\"/content/washer.v1i.multiclass/\"+i):\n",
        "        if j.endswith(\".jpg\") == True:\n",
        "          realimages.append(\"/content/washer.v1i.multiclass/\"+i+\"/\"+j)\n",
        "          reallabels.append(\"washer\")\n",
        "a=0\n",
        "for i in os.listdir(\"/content/test\"):\n",
        "  for j in os.listdir(\"/content/test/\"+i):\n",
        "      if a>250:\n",
        "          break\n",
        "      realimages.append(\"/content/test/\"+i+\"/\"+j)\n",
        "      reallabels.append(\"nut\")\n",
        "      a+=1"
      ],
      "metadata": {
        "id": "mlrpuHRgv2Mk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "syntheticimages=[]\n",
        "syntheticlabels=[]\n",
        "for i in os.listdir(\"/content/synthetic\"):\n",
        "  for j in os.listdir(\"/content/synthetic/\"+i):\n",
        "    if j.endswith(\".jpg\") == True:\n",
        "      syntheticimages.append(\"/content/synthetic/\"+i+\"/\"+j)\n",
        "      syntheticlabels.append(i)"
      ],
      "metadata": {
        "id": "XtfC_3Wlws-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "dfs=pd.DataFrame({'X':syntheticimages,'Y':syntheticlabels})\n",
        "dfs=pd.get_dummies(dfs,columns=['Y'],dtype=float)\n",
        "dfs.columns = dfs.columns.str.replace(\"Y_\", \"\")\n",
        "\n",
        "dfr=pd.DataFrame({'X':realimages,'Y':reallabels})\n",
        "dfr=pd.get_dummies(dfr,columns=['Y'],dtype=float)\n",
        "dfr.columns = dfr.columns.str.replace(\"Y_\", \"\")\n",
        "\n",
        "dfr.head()\n",
        "dfs.head()\n"
      ],
      "metadata": {
        "id": "CjfURt-LyE7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "class customdataset(Dataset):\n",
        "    def __init__(self,x,y,transform=None):\n",
        "        self.x=x\n",
        "        self.y=y\n",
        "        self.transform=transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.x.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        imgpath=self.x.iloc[index]\n",
        "        if self.transform:\n",
        "            image=Image.open(imgpath).convert(\"RGB\")\n",
        "            image=self.transform(image)\n",
        "        label_row = self.y.iloc[index, 0:2]\n",
        "        label_tensor = torch.tensor(label_row.values.astype(np.float32))\n",
        "        label_index = torch.argmax(label_tensor).item()\n",
        "\n",
        "        return image,label_index"
      ],
      "metadata": {
        "id": "fOtO8Jm50dh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "synthetic_transforms = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.3, contrast=0.3),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet stats\n",
        "])"
      ],
      "metadata": {
        "id": "nwqZaIr6zj3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_transforms = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "lbrNlHXR7JjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "xstrain, xstest,ystrain,ystest = train_test_split(dfs['X'],dfs[l],random_state=42, test_size=0.2)"
      ],
      "metadata": {
        "id": "cWYTJqnQxx7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "traindataset=customdataset(x=xstrain,y=ystrain,transform=synthetic_transforms)\n",
        "valdataset=customdataset(x=xstest,y=ystest,transform=synthetic_transforms)\n",
        "\n",
        "trainloader=DataLoader(traindataset,batch_size=40,shuffle=True)\n",
        "valloader=DataLoader(valdataset,batch_size=40,shuffle=True)"
      ],
      "metadata": {
        "id": "KsC6VJXa3rQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testmodel = models.densenet121(pretrained=False)"
      ],
      "metadata": {
        "id": "CBJ7XJUpztot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testmodel.classifier = torch.nn.Linear(testmodel.classifier.in_features, 2)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(testmodel.parameters(), lr=0.001)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "testmodel = testmodel.to(device)"
      ],
      "metadata": {
        "id": "NoxfYo-w0OFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 3\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    testmodel.train()\n",
        "    trunningloss,vrunningloss=0.0,0.0\n",
        "    ttotal,vtotal = 0,0\n",
        "    tacc,vacc=0.0,0.0\n",
        "    for inputs, labels in trainloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = testmodel(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        trunningloss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)  # Get predicted class\n",
        "        ttotal += labels.size(0)\n",
        "        tacc += (predicted == labels).sum().item()\n",
        "\n",
        "\n",
        "    testmodel.eval()\n",
        "    with torch.no_grad():\n",
        "      for inputs, labels in valloader:\n",
        "          inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "          outputs = testmodel(inputs)\n",
        "          loss = criterion(outputs, labels)\n",
        "          vrunningloss += loss.item()\n",
        "\n",
        "          _, predicted = torch.max(outputs.data, 1)  # Get predicted class\n",
        "          vtotal += labels.size(0)\n",
        "          vacc += (predicted == labels).sum().item()\n",
        "\n",
        "    print(\"=\"*20)\n",
        "    print(f\"\"\"Epoch {epoch+1}\n",
        "          train\n",
        "          Loss: {trunningloss/len(trainloader)}\n",
        "          Accuracy: {tacc*100/ttotal}\n",
        "          val\n",
        "          Loss: {vrunningloss/len(valloader)}\n",
        "          Accuracy: {vacc*100/vtotal}\n",
        "          \"\"\")"
      ],
      "metadata": {
        "id": "oLPzLjA_49Y6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xtrain, xtest,ytrain,ytest = train_test_split(dfr['X'],dfr[l],random_state=42, test_size=0.2)\n",
        "xtest, xval,ytest,yval = train_test_split(xtest,ytest,random_state=42, test_size=0.5)"
      ],
      "metadata": {
        "id": "6OjI2dNz6WZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "traindataset=customdataset(x=xtrain,y=ytrain,transform=real_transforms)\n",
        "testdataset=customdataset(x=xtest,y=ytest,transform=real_transforms)\n",
        "valdataset=customdataset(x=xval,y=yval,transform=real_transforms)\n",
        "\n",
        "trainloader=DataLoader(traindataset,batch_size=10,shuffle=True)\n",
        "testloader=DataLoader(testdataset,batch_size=10,shuffle=True)\n",
        "valloader=DataLoader(valdataset,batch_size=10,shuffle=True)"
      ],
      "metadata": {
        "id": "2AE9U8pH7FDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param in testmodel.features.parameters():\n",
        "    param.requires_grad = False\n",
        "optimizer = torch.optim.Adam(testmodel.classifier.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "id": "8aROWlw45m9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    testmodel.train()\n",
        "    trunningloss,vrunningloss=0.0,0.0\n",
        "    ttotal,vtotal = 0,0\n",
        "    tacc,vacc=0.0,0.0\n",
        "    for inputs, labels in trainloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = testmodel(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        trunningloss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)  # Get predicted class\n",
        "        ttotal += labels.size(0)\n",
        "        tacc += (predicted == labels).sum().item()\n",
        "\n",
        "\n",
        "    testmodel.eval()\n",
        "    with torch.no_grad():\n",
        "      for inputs, labels in valloader:\n",
        "          inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "          outputs = testmodel(inputs)\n",
        "          loss = criterion(outputs, labels)\n",
        "          vrunningloss += loss.item()\n",
        "\n",
        "          _, predicted = torch.max(outputs.data, 1)  # Get predicted class\n",
        "          vtotal += labels.size(0)\n",
        "          vacc += (predicted == labels).sum().item()\n",
        "\n",
        "    print(\"=\"*20)\n",
        "    print(f\"\"\"Epoch {epoch+1}\n",
        "          train\n",
        "          Loss: {trunningloss/len(trainloader)}\n",
        "          Accuracy: {tacc*100/ttotal}\n",
        "          val\n",
        "          Loss: {vrunningloss/len(valloader)}\n",
        "          Accuracy: {vacc*100/vtotal}\n",
        "          \"\"\")"
      ],
      "metadata": {
        "id": "LPAE9FMl7qPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "terunningloss,teacc=0.0,0.0\n",
        "tetotal=0\n",
        "\n",
        "testmodel.eval()\n",
        "with torch.no_grad():\n",
        "  for inputs, labels in testloader:\n",
        "      inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      outputs = testmodel(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "      terunningloss += loss.item()\n",
        "\n",
        "      _, predicted = torch.max(outputs.data, 1)  # Get predicted class\n",
        "      tetotal += labels.size(0)\n",
        "      teacc += (predicted == labels).sum().item()\n",
        "\n",
        "print(\"=\"*20)\n",
        "print(f\"\"\"\n",
        "      train\n",
        "      Loss: {terunningloss/len(testloader)}\n",
        "      Accuracy: {teacc*100/tetotal}\n",
        "      \"\"\")"
      ],
      "metadata": {
        "id": "s9XtfAM87ymz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}